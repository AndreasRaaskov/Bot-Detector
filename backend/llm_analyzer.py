# llm_analyzer.py - Large Language Model integration for bot detection
# This module provides a model-agnostic way to use different LLMs for analyzing if content is AI-generated
# Supports OpenAI, Anthropic (Claude), Google (Gemini), and local models via Ollama

import asyncio
import json
import logging
from typing import List, Optional, Dict, Any, Union
from enum import Enum
import httpx

try:
    from .models import LLMAnalysisResult
except Exception:
    from models import LLMAnalysisResult

logger = logging.getLogger(__name__)

class LLMProvider(Enum):
    """
    Supported LLM providers
    Each provider has different API formats and capabilities
    """
    OPENAI = "openai"
    ANTHROPIC = "anthropic" 
    GOOGLE = "google"
    OLLAMA = "ollama"  # For local models

class LLMAnalyzer:
    """
    Model-agnostic LLM analyzer for detecting AI-generated content
    
    This class provides a unified interface for different LLM providers.
    It can automatically try multiple providers if one fails, and includes
    retry logic and error handling.
    """
    
    def __init__(self, api_keys: Dict[str, str], default_models: Optional[Dict[str, str]] = None):
        """
        Initialize the LLM analyzer with API keys and model preferences
        
        Args:
            api_keys: Dictionary mapping provider names to API keys
                     e.g., {"openai": "sk-...", "anthropic": "sk-ant-..."}
            default_models: Dictionary mapping providers to preferred models
                           e.g., {"openai": "gpt-4", "anthropic": "claude-3-sonnet"}
        """
        self.api_keys = api_keys
        
        # Set default models for each provider
        self.default_models = default_models or {
            "openai": "gpt-5.1-2025-11-13",  # Cost-effective model for this task
            "anthropic": "claude-3-haiku-20240307",  # Fast and cost-effective
            "google": "gemini-1.5-flash",  # Good balance of speed and quality
            "ollama": "llama3.2:3b"  # Small local model
        }
        
        # Create HTTP client for API calls
        self.client = httpx.AsyncClient(timeout=60.0)
        
        # Define the analysis prompt that will be sent to LLMs
        self.analysis_prompt = """
        You are analyzing social media content to determine if it was written by a human or generated by AI.

        Please analyze the following content and determine if it appears to be AI-generated:

        PROFILE BIO: {bio}
        
        RECENT POSTS:
        {posts}

        Based on this content, please provide:
        1. Your assessment: Is this likely human-written or AI-generated?
        2. Confidence level (0-100%)
        3. Key indicators that influenced your decision
        4. A brief explanation of your reasoning

        Respond in JSON format:
        {{
            "assessment": "human" or "ai",
            "confidence": 85,
            "indicators": ["list", "of", "key", "indicators"],
            "reasoning": "Brief explanation of why you think this"
        }}
        """
    
    async def analyze_content(self, posts: List[str], bio: str = "", 
                            preferred_provider: Optional[str] = None) -> LLMAnalysisResult:
        """
        Analyze content using LLMs to detect AI generation
        
        Args:
            posts: List of post texts to analyze
            bio: User's profile bio/description
            preferred_provider: Which LLM provider to try first
            
        Returns:
            LLMAnalysisResult with the analysis results
        """
        try:
            # Prepare the content for analysis
            posts_text = "\n".join([f"- {post}" for post in posts[:20]])  # Limit to 20 posts
            formatted_prompt = self.analysis_prompt.format(
                bio=bio or "No bio provided",
                posts=posts_text or "No posts provided"
            )
            
            # Try different providers in order of preference
            providers_to_try = self._get_provider_order(preferred_provider)
            
            for provider in providers_to_try:
                try:
                    logger.info(f"Trying analysis with {provider}")
                    result = await self._analyze_with_provider(provider, formatted_prompt)
                    if result:
                        return result
                except Exception as e:
                    logger.warning(f"Analysis failed with {provider}: {e}")
                    continue
            
            # If all providers fail, return a neutral result
            logger.error("All LLM providers failed")
            return LLMAnalysisResult(
                model_used="unknown",
                confidence=0.0,
                reasoning="Analysis failed - all LLM providers unavailable",
                score=0.5  # Neutral score when we can't analyze
            )
            
        except Exception as e:
            logger.error(f"LLM analysis error: {e}")
            return LLMAnalysisResult(
                model_used="error",
                confidence=0.0,
                reasoning=f"Analysis error: {str(e)}",
                score=0.5
            )
    
    def _get_provider_order(self, preferred_provider: Optional[str]) -> List[str]:
        """
        Get the order in which to try LLM providers
        
        Args:
            preferred_provider: Provider to try first
            
        Returns:
            List of provider names in order of preference
        """
        available_providers = []
        
        # Check which providers we have API keys for
        for provider in ["openai", "anthropic", "google", "ollama"]:
            if provider == "ollama":
                # Ollama is local, so always available if specified
                available_providers.append(provider)
            elif self.api_keys.get(provider):
                available_providers.append(provider)
        
        # If a preferred provider is specified and available, put it first
        if preferred_provider and preferred_provider in available_providers:
            available_providers.remove(preferred_provider)
            available_providers.insert(0, preferred_provider)
        
        return available_providers
    
    async def _analyze_with_provider(self, provider: str, prompt: str) -> Optional[LLMAnalysisResult]:
        """
        Analyze content with a specific LLM provider
        
        Args:
            provider: The LLM provider to use
            prompt: The formatted prompt to send
            
        Returns:
            LLMAnalysisResult if successful, None if failed
        """
        try:
            if provider == "openai":
                return await self._analyze_with_openai(prompt)
            elif provider == "anthropic":
                return await self._analyze_with_anthropic(prompt)
            elif provider == "google":
                return await self._analyze_with_google(prompt)
            elif provider == "ollama":
                return await self._analyze_with_ollama(prompt)
            else:
                logger.warning(f"Unknown provider: {provider}")
                return None
        except Exception as e:
            logger.error(f"Provider {provider} analysis failed: {e}")
            return None
    
    async def _analyze_with_openai(self, prompt: str) -> Optional[LLMAnalysisResult]:
        """Analyze content using OpenAI's API"""
        if "openai" not in self.api_keys:
            return None
        
        headers = {
            "Authorization": f"Bearer {self.api_keys['openai']}",
            "Content-Type": "application/json"
        }
        
        data = {
            "model": self.default_models["openai"],
            "messages": [
                {"role": "system", "content": "You are an expert at detecting AI-generated content on social media."},
                {"role": "user", "content": prompt}
            ],
            "temperature": 0.1,  # Low temperature for consistent analysis
            "max_tokens": 1000
        }
        
        response = await self.client.post(
            "https://api.openai.com/v1/chat/completions",
            headers=headers,
            json=data
        )
        
        if response.status_code == 200:
            result = response.json()
            content = result["choices"][0]["message"]["content"]
            return self._parse_llm_response(content, f"openai/{self.default_models['openai']}")
        else:
            logger.error(f"OpenAI API error: {response.status_code} {response.text}")
            return None
    
    async def _analyze_with_anthropic(self, prompt: str) -> Optional[LLMAnalysisResult]:
        """Analyze content using Anthropic's Claude API"""
        if "anthropic" not in self.api_keys:
            return None
        
        headers = {
            "x-api-key": self.api_keys["anthropic"],
            "Content-Type": "application/json",
            "anthropic-version": "2023-06-01"
        }
        
        data = {
            "model": self.default_models["anthropic"],
            "max_tokens": 1000,
            "temperature": 0.1,
            "messages": [
                {"role": "user", "content": prompt}
            ]
        }
        
        response = await self.client.post(
            "https://api.anthropic.com/v1/messages",
            headers=headers,
            json=data
        )
        
        if response.status_code == 200:
            result = response.json()
            content = result["content"][0]["text"]
            return self._parse_llm_response(content, f"anthropic/{self.default_models['anthropic']}")
        else:
            logger.error(f"Anthropic API error: {response.status_code} {response.text}")
            return None
    
    async def _analyze_with_google(self, prompt: str) -> Optional[LLMAnalysisResult]:
        """Analyze content using Google's Gemini API"""
        if "google" not in self.api_keys:
            return None
        
        # Google Gemini API endpoint
        url = f"https://generativelanguage.googleapis.com/v1beta/models/{self.default_models['google']}:generateContent"
        
        headers = {
            "Content-Type": "application/json"
        }
        
        data = {
            "contents": [
                {
                    "parts": [
                        {"text": prompt}
                    ]
                }
            ],
            "generationConfig": {
                "temperature": 0.1,
                "maxOutputTokens": 1000
            }
        }
        
        # Add API key as query parameter for Google
        params = {"key": self.api_keys["google"]}
        
        response = await self.client.post(url, headers=headers, json=data, params=params)
        
        if response.status_code == 200:
            result = response.json()
            content = result["candidates"][0]["content"]["parts"][0]["text"]
            return self._parse_llm_response(content, f"google/{self.default_models['google']}")
        else:
            logger.error(f"Google API error: {response.status_code} {response.text}")
            return None
    
    async def _analyze_with_ollama(self, prompt: str) -> Optional[LLMAnalysisResult]:
        """Analyze content using local Ollama models"""
        try:
            # Ollama typically runs on localhost:11434
            data = {
                "model": self.default_models["ollama"],
                "prompt": prompt,
                "stream": False,
                "options": {
                    "temperature": 0.1,
                    "num_predict": 1000
                }
            }
            
            response = await self.client.post(
                "http://localhost:11434/api/generate",
                json=data
            )
            
            if response.status_code == 200:
                result = response.json()
                content = result["response"]
                return self._parse_llm_response(content, f"ollama/{self.default_models['ollama']}")
            else:
                logger.error(f"Ollama error: {response.status_code} {response.text}")
                return None
                
        except Exception as e:
            logger.info(f"Ollama not available (this is normal if not installed): {e}")
            return None
    
    def _parse_llm_response(self, response_text: str, model_name: str) -> LLMAnalysisResult:
        """
        Parse the LLM response into a structured result
        
        Args:
            response_text: Raw response from the LLM
            model_name: Name/identifier of the model used
            
        Returns:
            LLMAnalysisResult with parsed data
        """
        try:
            # Try to extract JSON from the response
            # LLMs sometimes add extra text around the JSON
            json_start = response_text.find('{')
            json_end = response_text.rfind('}') + 1
            
            if json_start >= 0 and json_end > json_start:
                json_text = response_text[json_start:json_end]
                parsed = json.loads(json_text)
                
                # Extract values with fallbacks
                assessment = parsed.get("assessment", "unknown").lower()
                confidence = float(parsed.get("confidence", 50)) / 100.0  # Convert to 0-1 scale
                indicators = parsed.get("indicators", [])
                reasoning = parsed.get("reasoning", "No reasoning provided")
                
                # Convert assessment to bot score (1 = bot, 0 = human)
                if assessment == "ai":
                    bot_score = confidence
                elif assessment == "human":
                    bot_score = 1.0 - confidence
                else:
                    bot_score = 0.5  # Unknown/neutral
                
                # Add indicators to reasoning for more complete explanation
                if indicators:
                    reasoning += f" Key indicators: {', '.join(indicators)}"
                
                return LLMAnalysisResult(
                    model_used=model_name,
                    confidence=confidence,
                    reasoning=reasoning,
                    score=bot_score
                )
            
            else:
                # If we can't parse JSON, try to extract useful info from free text
                reasoning = response_text[:500]  # Limit length
                
                # Simple keyword-based scoring
                ai_keywords = ["ai-generated", "artificial", "automated", "bot", "generated"]
                human_keywords = ["human", "authentic", "personal", "genuine"]
                
                ai_count = sum(1 for keyword in ai_keywords if keyword in response_text.lower())
                human_count = sum(1 for keyword in human_keywords if keyword in response_text.lower())
                
                if ai_count > human_count:
                    score = 0.7  # Likely bot
                elif human_count > ai_count:
                    score = 0.3  # Likely human
                else:
                    score = 0.5  # Uncertain
                
                return LLMAnalysisResult(
                    model_used=model_name,
                    confidence=0.5,  # Low confidence due to parsing failure
                    reasoning=f"Could not parse structured response. Raw assessment: {reasoning}",
                    score=score
                )
                
        except Exception as e:
            logger.error(f"Error parsing LLM response: {e}")
            return LLMAnalysisResult(
                model_used=model_name,
                confidence=0.0,
                reasoning=f"Failed to parse response: {str(e)}",
                score=0.5
            )
    
    async def close(self):
        """Clean up HTTP client resources"""
        await self.client.aclose()
    
    async def __aenter__(self):
        """Support for async context manager"""
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """Support for async context manager - automatically clean up"""
        await self.close()